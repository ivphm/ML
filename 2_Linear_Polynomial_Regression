import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

x = np.loadtxt('HW1_data/2/hw1x.dat')
y = np.loadtxt('HW1_data/2/hw1y.dat')

### Part a) ###

# Add column vector of 1s
X = np.column_stack((np.ones_like(x), x))

# Closed-form 
def closed_form(X, y):
    return np.linalg.inv(X.T @ X) @ X.T @ y 

theta = closed_form(X, y)
print("Theta (closed-form):", theta)

# Plot
plt.scatter(x, y, label="Data")
plt.plot(x, X @ theta, color='red', label="Linear Fit")
plt.legend()
plt.show()

# Empirical risk function
def empirical_risk(X, y, theta):
    residuals = y - X @ theta
    return np.mean(0.5 * residuals**2)

error = empirical_risk(X, y, theta)
print("Training error (closed-form):", error)

### Part b) ###

# Gradient descent
def gradient_descent(X, y, lr=0.01, epochs=5):
    theta = np.zeros(X.shape[1])
    for _ in range(epochs):
        gradient = -X.T @ (y - X @ theta) / len(y)
        theta -= lr * gradient
    return theta

# Stochastic gradient descent
def sgd(X, y, lr=0.01, epochs=5):
    theta = np.zeros(X.shape[1])
    for _ in range(epochs):
        for i in range(len(y)):
            xi = X[i:i+1]
            yi = y[i]
            gradient = -xi.T * (yi - xi @ theta)
            theta -= lr * gradient.ravel()
    return theta

theta_gd = gradient_descent(X, y)
print("Theta (GD):", theta_gd)
print("Training error (GD):", empirical_risk(X, y, theta_gd))

theta_sgd = sgd(X, y)
print("Theta (SGD):", theta_sgd)
print("Training error (SGD):", empirical_risk(X, y, theta_sgd))

### Part c) ###

# Polynomial Regression
def PolyRegress(x, y, d):
    X_poly = np.column_stack([x**i for i in range(d + 1)])
    theta = closed_form(X_poly, y)
    error = empirical_risk(X_poly, y, theta)
    return theta, error, X_poly

# Quadratic Fit
theta_quad, error_quad, X_quad = PolyRegress(x, y, 2)
plt.scatter(x, y)
plt.plot(x, X_quad @ theta_quad, label="Quadratic Fit", color='orange')
plt.legend()
plt.show()
print("Quadratic fit error:", error_quad)

# 3rd order to 15th order fit
errors = []
for d in range(3, 16):
    _, err, _ = PolyRegress(x, y, d)
    errors.append(err)
    print(f"Degree {d} error: {err}")

# Overfitting Point
plt.plot(range(3, 15), errors, marker='o')
plt.xlabel("Polynomial Degree")
plt.ylabel("Training Error")
plt.title("Training Error vs Polynomial Degree")
plt.show()